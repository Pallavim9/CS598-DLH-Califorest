{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc_HCYzVTkQ3",
        "outputId": "53459cc0-6a42-4c88-8b9d-ae02272b5135"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/yubin-park/califorest.git\n",
        "%cd califorest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWVfCWvSTzKc",
        "outputId": "fb83aa77-c8ce-4612-bbfa-497b2d496fd9"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pandas scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6fCglJ6UKrc",
        "outputId": "0c8a8bab-e163-4bca-a5e4-e39492d89d92"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Replace with path to dataset.\n",
        "data = pd.read_csv('Synthetic_MIMIC-III_Dataset.csv')\n",
        "\n",
        "print(data.head())\n",
        "print(data.columns)\n",
        "\n",
        "# Split data into features and target\n",
        "X = data.drop('mortality_risk', axis=1)\n",
        "y = data['mortality_risk']\n",
        "\n",
        "# Check shapes to confirm split worked\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "ATGznUHHVQUd",
        "outputId": "970dbab6-a28f-4bc0-c4a1-ccc9f73cf53b"
      },
      "outputs": [],
      "source": [
        "# First, check what's available in the repository\n",
        "!ls -la /content/califorest/\n",
        "!ls -la /content/califorest/califorest/\n",
        "# See what's in the califorest module\n",
        "import CaliForest\n",
        "print(dir(califorest))\n",
        "\n",
        "!cat /content/califorest/califorest/__init__.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXRNJISrVdp0",
        "outputId": "453bfefb-f36f-463e-e602-9431d6f42300"
      },
      "outputs": [],
      "source": [
        "# Check the documentation for the CaliForest class\n",
        "import inspect\n",
        "from califorest import CaliForest\n",
        "\n",
        "# Print the class signature\n",
        "print(inspect.signature(CaliForest.__init__))\n",
        "\n",
        "# If available, print docstring\n",
        "print(CaliForest.__doc__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDDl8gciU-72",
        "outputId": "cdbea367-133b-47f8-a90d-533948009ed8"
      },
      "outputs": [],
      "source": [
        "# Create our own implementation of CaliForest with updated scikit-learn compatibility\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "class MyCalibForest:\n",
        "    def __init__(self,\n",
        "                 n_estimators=300,\n",
        "                 criterion='gini',\n",
        "                 max_depth=5,\n",
        "                 min_samples_split=2,\n",
        "                 min_samples_leaf=1,\n",
        "                 ctype='isotonic',\n",
        "                 alpha0=100,\n",
        "                 beta0=25):\n",
        "        \"\"\"\n",
        "        Implementation of CaliForest that works with modern scikit-learn\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        n_estimators : int, default=300\n",
        "            Number of trees in the forest\n",
        "        criterion : str, default='gini'\n",
        "            Function to measure the quality of a split\n",
        "        max_depth : int, default=5\n",
        "            Maximum depth of the trees\n",
        "        min_samples_split : int, default=2\n",
        "            Minimum number of samples required to split a node\n",
        "        min_samples_leaf : int, default=1\n",
        "            Minimum number of samples required at a leaf node\n",
        "        ctype : str, default='isotonic'\n",
        "            Calibration method ('isotonic' or 'sigmoid')\n",
        "        alpha0, beta0 : float, default=100, 25\n",
        "            Prior parameters for calibration\n",
        "        \"\"\"\n",
        "        self.n_estimators = n_estimators\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.ctype = ctype\n",
        "        self.alpha0 = alpha0\n",
        "        self.beta0 = beta0\n",
        "\n",
        "        # Create base estimator\n",
        "        self.base_estimator = RandomForestClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            criterion=criterion,\n",
        "            max_depth=max_depth,\n",
        "            min_samples_split=min_samples_split,\n",
        "            min_samples_leaf=min_samples_leaf,\n",
        "            max_features=\"sqrt\",  # Using 'sqrt' instead of 'auto'\n",
        "            bootstrap=True,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit the calibrated classifier\"\"\"\n",
        "        # Use 'base_estimator'\n",
        "        self.calibrated_clf = CalibratedClassifierCV(\n",
        "            estimator=self.base_estimator, \n",
        "            method=self.ctype,\n",
        "            cv=5\n",
        "        )\n",
        "        self.calibrated_clf.fit(X, y)\n",
        "        self.classes_ = self.calibrated_clf.classes_\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Predict class probabilities\"\"\"\n",
        "        return self.calibrated_clf.predict_proba(X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict class labels\"\"\"\n",
        "        return self.calibrated_clf.predict(X)\n",
        "\n",
        "    @property\n",
        "    def feature_importances_(self):\n",
        "        \"\"\"Get feature importances from the base estimator\"\"\"\n",
        "        try:\n",
        "            return self.calibrated_clf.estimator.feature_importances_\n",
        "        except:\n",
        "            try:\n",
        "                return self.calibrated_clf.estimators_[0].estimator.feature_importances_\n",
        "            except:\n",
        "                rf = RandomForestClassifier(\n",
        "                    n_estimators=self.n_estimators,\n",
        "                    criterion=self.criterion,\n",
        "                    max_depth=self.max_depth,\n",
        "                    random_state=42\n",
        "                )\n",
        "                rf.fit(X_train, y_train)\n",
        "                return rf.feature_importances_\n",
        "\n",
        "# Split data into train/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize our custom model\n",
        "model = MyCalibForest(\n",
        "    n_estimators=300,\n",
        "    criterion='gini',\n",
        "    max_depth=5,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    ctype='isotonic'\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model using classification metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Get probability estimates for ROC curves\n",
        "y_prob = model.predict_proba(X_test)\n",
        "print(f\"Probability shape: {y_prob.shape}\")\n",
        "print(\"Sample probabilities:\")\n",
        "print(y_prob[:5])  # Show first 5 probability predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3KqPnUAhHtkP",
        "outputId": "6590a314-cd71-4496-9e40-0ba801b03956"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
        "\n",
        "# Get probability estimates for ROC curve\n",
        "y_prob = model.predict_proba(X_test)[:, 1]  # Get probability of positive class\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Random prediction line\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(recall, precision, label='Precision-Recall curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Feature importance\n",
        "if hasattr(model, 'feature_importances_'):\n",
        "    importances = model.feature_importances_\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.bar(range(X.shape[1]), importances[indices])\n",
        "    plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
        "    plt.xlabel('Features')\n",
        "    plt.ylabel('Importance')\n",
        "    plt.title('Feature Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Confusion matrix visualization\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "ZSXYOvrvIC-Z",
        "outputId": "49bd294d-8491-4733-bdaa-c29dd9944e0c"
      },
      "outputs": [],
      "source": [
        "# Create models with different hyperparameters\n",
        "models = {\n",
        "    'Default': MyCalibForest(),\n",
        "    'Deep Trees': MyCalibForest(max_depth=10),\n",
        "    'More Trees': MyCalibForest(n_estimators=500),\n",
        "    'Fewer Trees': MyCalibForest(n_estimators=100),\n",
        "    'Min Samples Split 5': MyCalibForest(min_samples_split=5),\n",
        "    'Min Samples Leaf 5': MyCalibForest(min_samples_leaf=5),\n",
        "    'Entropy Criterion': MyCalibForest(criterion='entropy'),\n",
        "    'Sigmoid Calibration': MyCalibForest(ctype='sigmoid')\n",
        "}\n",
        "\n",
        "import pandas as pd\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    results[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1': f1}\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)\n",
        "\n",
        "# Plot results\n",
        "results_df.plot(kind='bar', figsize=(14, 8))\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "5QBuJKA8IVHU",
        "outputId": "d8a35f9b-f084-4de1-a4db-e22510f1d043"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Train comparison models\n",
        "models = {\n",
        "    'CaliForest': MyCalibForest(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'SVM': SVC(probability=True, random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    results[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1': f1}\n",
        "\n",
        "# Display results\n",
        "comparison_df = pd.DataFrame(results).T\n",
        "print(comparison_df)\n",
        "\n",
        "# Plot results\n",
        "comparison_df.plot(kind='bar', figsize=(12, 6))\n",
        "plt.title('Model Comparison')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
